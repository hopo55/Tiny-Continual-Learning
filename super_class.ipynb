{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import dataloaders\n",
    "from dataloaders.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CIFAR100'\n",
    "\n",
    "# prepare dataloader\n",
    "if dataset == 'CIFAR10':\n",
    "    Dataset = dataloaders.iCIFAR10\n",
    "    num_classes = 10\n",
    "elif dataset == 'CIFAR100':\n",
    "    Dataset = dataloaders.iCIFAR100\n",
    "    num_classes = 100\n",
    "elif dataset == 'TinyIMNET':\n",
    "    Dataset = dataloaders.iTinyIMNET\n",
    "    num_classes = 200\n",
    "else:\n",
    "    Dataset = dataloaders.H5Dataset\n",
    "    num_classes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tasks\n",
    "rand_split = True\n",
    "class_order = np.arange(num_classes).tolist()\n",
    "class_order_logits = np.arange(num_classes).tolist()\n",
    "if seed > 0 and rand_split:\n",
    "    random.shuffle(class_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "tasks_logits = []\n",
    "p = 0\n",
    "first_split_size = 5\n",
    "other_split_size = 5\n",
    "\n",
    "while p < num_classes:\n",
    "    inc = other_split_size if p > 0 else first_split_size\n",
    "    tasks.append(class_order[p:p+inc])\n",
    "    tasks_logits.append(class_order_logits[p:p+inc])\n",
    "    p += inc\n",
    "num_tasks = len(tasks)\n",
    "task_names = [str(i+1) for i in range(num_tasks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2 # Append transform image and buffer image\n",
    "ky = 1 # Not append transform for memory buffer\n",
    "\n",
    "# datasets and dataloaders\n",
    "dataroot = 'data'\n",
    "labeled_samples = 10000 # image per task of CIFAR dataset \n",
    "unlabeled_task_samples = -1\n",
    "l_dist = 'super' # if l_dist is super, then resample task\n",
    "ul_dist = None\n",
    "validation = False\n",
    "repeat = 1\n",
    "\n",
    "train_aug = True\n",
    "train_transform = dataloaders.utils.get_transform(dataset=dataset, phase='train', aug=train_aug)\n",
    "train_transformb = dataloaders.utils.get_transform(dataset=dataset, phase='train', aug=train_aug, hard_aug=True)\n",
    "test_transform  = dataloaders.utils.get_transform(dataset=dataset, phase='test', aug=train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(dataroot, dataset, labeled_samples, unlabeled_task_samples, train=True, lab = True,\n",
    "                        download=True, transform=TransformK(train_transform, train_transform, ky), l_dist=l_dist, ul_dist=ul_dist,\n",
    "                        tasks=tasks, seed=seed, rand_split=rand_split, validation=validation, kfolds=repeat)\n",
    "train_dataset_ul = Dataset(dataroot, dataset, labeled_samples, unlabeled_task_samples, train=True, lab = False,\n",
    "                        download=True, transform=TransformK(train_transform, train_transformb, k), l_dist=l_dist, ul_dist=ul_dist,\n",
    "                        tasks=tasks, seed=seed, rand_split=rand_split, validation=validation, kfolds=repeat)\n",
    "test_dataset  = Dataset(dataroot, dataset, train=False,\n",
    "                        download=False, transform=test_transform, l_dist=l_dist, ul_dist=ul_dist,\n",
    "                        tasks=tasks, seed=seed, rand_split=rand_split, validation=validation, kfolds=repeat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('hspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7200c97f9580f269913cae0521a31c8c9bc2a022b66e7eee6f7caa3cb908faad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
